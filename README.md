## Speech Emotion Recognition Using Machine Learning and Deep Learning
## Abstract 

This project explores Speech Emotion Recognition (SER) using machine learning and deep learning techniques. By leveraging feature extraction methods and advanced neural network architectures, we aim to accurately classify emotion from audio signals. Our approach involves preprocessing audio data, extracting relevant features, and training models like convolutional neural networks (CNNs)and recurrent neural networks (RNs). Experimental results demonstrate significant improvements in emotion detection accuracy, highlighting the potential of deep learning in enhancing human_computer interaction through effective emotion recognition.
## Dataset Used
# TESS

There are a set of 200 target words were spoken in the carrier phase "Say the word' by two actresses (aged 26 and 64 years) and recordings were made of the set portraying each of seven emotions( anger, disgust, fear, happiness, pleasure, surprise, sadness and neutral). There are 2800 data points( audio files) in total. The dataset is organised such as that each of the two female actor and their emotions are contain withing its own folder. And within that, all 200 tragt words audio file can be found. The format of the udio files is a WAV format.## Confusion Matrix
## Confusion Matrix

In this project, we evaluated the perfomance of CNN, RNN, & LSTM models for Speech Emotion Recognition (SER) using confusion matrix.